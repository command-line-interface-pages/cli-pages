# xidel

> Download and extract data from HTML/XML pages as well as JSON APIs
> More information: https://www.videlibri.de/xidel.html

- Print all URLs found by a Google search:

`xidel {string value: https://www.google.com/search?q=test} --extract "//a/extract(@href, 'url[?]q=([^&]+)&', 1)[. != '']"`

- Print the title of all pages found by a Google search and download them:

`xidel {string value: https://www.google.com/search?q=test} --follow "{string value: //a/extract(@href, 'url[?]q=([^&]+)&', 1)[. != '']}" --extract {string value: //title} --download {{'{$host}/'}}`

- Follow all links on a page and print the titles, with XPath:

`xidel {string value: https://example.org} --follow {string value: //a} --extract {string value: //title}`

- Follow all links on a page and print the titles, with CSS selectors:

`xidel {string value: https://example.org} --follow "{string value: css('a')}" --css {string value: title}`

- Follow all links on a page and print the titles, with pattern matching:

`xidel {string value: https://example.org} --follow "{{<a>{.}</a>*}}" --extract "{{<title>{.}</title>}}"`

- Read the pattern from example.xml (which will also check if the element containing "ood" is there, and fail otherwise):

`xidel {string value: path/to/example.xml} --extract "{{<x><foo>ood</foo><bar>{.}</bar></x>}}"`

- Print all newest Stack Overflow questions with title and URL using pattern matching on their RSS feed:

`xidel {string value: http://stackoverflow.com/feeds} --extract "{{<entry><title>{title:=.}</title><link>{uri:=@href}</link></entry>+}}"`

- Check for unread Reddit mail, Webscraping, combining CSS, XPath, JSONiq, and automatically form evaluation:

`xidel {string value: https://reddit.com} --follow "{{form(css('form.login-form')[1], {'user': '$your_username', 'passwd': '$your_password'})}}" --extract "{string value: css('#mail')/@title}"`
